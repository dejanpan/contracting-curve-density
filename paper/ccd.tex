\documentclass[conference]{IEEEtran}
% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi

\usepackage{cite}
\usepackage{times}
\usepackage{wrapfig}
\usepackage{tweaklist}
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage{bm}
\usepackage{color}
\usepackage{colortbl}
\usepackage{subfig}
\usepackage[ruled,vlined]{algorithm2e}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\graphicspath{{../master_thesis/}}

\newcommand{\todo}[1]{\textbf{\textcolor{red}{TODO: #1}}}
\newcommand{\todos}[1]{\textbf{\textcolor{red}{TODO Shulei: #1}}}
\newcommand{\todod}[1]{\textbf{\textcolor{red}{TODO Dejan: #1}}}
\newcommand{\dones}[1]{\textbf{\textcolor{blue}{DONE Shulei: #1}}}
\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Contracting Curve Density Algorithm for Applications in Personal Robotics}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Shulei Zhu and Dejan Pangercic and Michael Beetz}
\IEEEauthorblockA{Intelligent Autonomous Systems Group, TU Munich \\
Email: \{shulei.zhu, pangercic, beetz\}@cs.tum.edu}
}

% make the title area
\maketitle

\begin{abstract}
This paper investigates an extended and optimized
implementation of the state-of-the-art local curve fitting algorithm
named Contracting Curve Density (CCD) algorithm, originally developed 
by Hanek et al. In particular, we investigate its application  
in the field of personal robotics for the tasks such as the segmentation
of objects in clutter and the tracking of objects. 
The developed system mainly consists of two functional parts, the CCD
algorithm to fit the model curve in still images and the CCD tracker to
track the model in the videos. We demonstrate algorithm's working 
in various scenes using handheld camera and the cameras from the 
PR2 robot. Achieved results show that the CCD algorithm achieves 
robustness and sub-pixel accuracy even in the presence of clutter, 
partial occlusion, and changes of illumination.
\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}
The CCD algorithm can be best described as follows. Given one or multiple images as input
data and a parametric curve model with a priori distribution of model
parameters, through curve-fitting process, we estimate the model
parameters which determine the approximation of the posterior
distribution in order to make the curve models best matching the image 
data~\cite{hanek2004contracting}.

The curve-fitting problem and its variants have a wide range of
applications in the field of robotics, medical processing, user
interface, surveillance and biometrics~\cite{hanek2004fitting}. In order to be
widely applicable to practical personal robotics problems (such as
perception of mobile manipulation), robustness,
accuracy, efficiency and versatility should be
considered when a novel approach is designed and implemented.
However, solving object segmentation and the
related object contour tracking problems are always challenging,
especially in natural and unconstrained scenes. Due to clutter,
shading, texture, and specular reflections it is very difficult to segment
an object from an inhomogeneous background. Furthermore, physical
conditions, such as the illumination or surface properties, will
influence the efficiency and stability of related approaches. 
We thus aim to introduce the substantial improvements to the original
version of CCD algorithm and thus devise a single criterion that is 
applicable for the segmentation of all kinds of objects' boundaries.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{images/divide1.jpg}\\
  \includegraphics[width=\columnwidth]{images/divide2.jpg}
  \caption{A classification problem: \textbf{Top:} The blue box was successfully segmented
    from the background. \textbf{Bottom:} The blue area is inside the curve while
    the golden area is outside.}
  \label{fig:divide}
\end{figure}

\subsection{An Alternative View of the CCD Algorithm}
\label{sec:overview}
In the field of pattern recognition, the key concept is that of
uncertainty. In image data, the uncertainty arises both
through noise from measurements, as well as through the nature of
the objects (e.g. cardiac motion and deformation). Probability theory
provides a consistent framework for the quantification and
manipulation of uncertainty.  In this section, we consider curve-fitting
problem from a probabilistic perspective and turn it into
a classification problem.

In the CCD algorithm, the aim is to find the contour of observed object
and thus segment it from the background. Therefore, a hypothetical 
contour divides the image into two parts (Fig.\ref{fig:divide}), inside
and outside. For probabilistic model, we can represent this using
binary representation (e.g. $\{0, 1\}$). The goal of the CCD algorithm
then becomes to accurately assign a class label to each pixel in the vicinity of the
contour and the curve-fitting problem thus becomes a classification
one. A powerful approach to solve this problem involves modeling of a
conditional probability distribution in an inference stage, and then
subsequently using this distribution to make optimal decisions. In
order to derive the conditional probability, prior distribution and
likelihood function should be given.

We assume that a parametric curve model is governed by a prior distribution
over the model parameters (usually a multi-dimensional vector). There
exists a range of probability distributions which can be used to model
the distribution of shapes. In this paper we consider the Gaussian distribution.

Defining the prior distribution is only a step of the problem.
According to the Bayesian theorem, the conditional distribution
is proportional to the product of prior distribution and the likelihood
function. Hence, the next step is to define the likelihood function.

In the implementation of the CCD algorithm local image pixel values are used
as the training data to determine the likelihood function. If the data is 
assumed to be drawn independently from the distribution, then the likelihood 
function is given by the accumulation of all the components.
By pixel value we denote the vector containing the local single- or multichannel
image data associated to a pixel (e.g. RGB values). 
However, other types of local features computed in a pre-processing
step may also be used, e.g. texture descriptors or color values in
other color spaces. The likelihood function obtained from the local statistics does
not have a closed-form solution. In addition, the prior distribution is just
an approximate to the true distribution. Since the maximization
likelihood method was proven \cite{bishop2006pattern} not to work here, we have to use an alternative
approach known as Iterative Reweighted Least Squares (IRLS) to find
the solution. Here the IRLS process is used to find the Maximum a Posterior (MAP)
estimate.

In the CCD algorithm, because we just need a parameter vector determining
the shape of the specified contour, we do not plan to calculate the
predictive distribution. Therefore, the MAP solution mentioned above
becomes our final objective function.

An important and decisive issue to consider is the fact that the exact inference for the
regression is always intractable. In the next sub-section we will discuss how we
solved this problem yet even improved the robustness and performance. 

\subsection{Key Contributions}
In order to improve the stability, accuracy and robustness over the original
implementation we introduce the following novel improvements. Firstly, we use 
the logistic sigmoid function instead of a Gaussian error function which renders a
curve-fitting problem as a Gaussian logistic problem~\footnote{For the two-class
classification problem, the posterior probability 
of class $C$ can be written as a \textbf{continous} logistic sigmoid acting
on a linear function of $x$ (equivalent to \textit{fuzzy assignment}).} known in the field of pattern 
recognition. Secondly, a quadratic or
a cubic B-spline curve is used to model the parametric curve
to avoid the Runge phenomenon~\cite{s√ºli2003introduction} without increasing the degree of the
B-spline. Thirdly, the system supports both planar affine (6-DOF) and
three-dimensional affine (8-DOF) shape-space. The latter affine space can avoid
curve mismatching caused by major viewpoint changes. Lastly, in
order to avoid manual intervention by the user, the developed system
also supports robust global initial curve initialization modules based on both keypoint
feature matching and projection of concave contours a priori designed mesh models.

In the remainder of this paper we first introduce the related approaches, 
in Section~\ref{sec:arch} we then shortly revisit an original implementation of 
CCD algorithm and continue with a presentation of our improvements over the
original idea (Section~\ref{sec:ccd_novelties}). In Section~\ref{sec:results}
we present the set of possible applications for CCD and evaluation thereof and
conclude with Section~\ref{sec:conclusions}.

\section{Related Work}
\label{sec:rw}
We will split this section based on the following three criteria:
\begin{itemize}
\item related work on two-dimensional and three-dimensional deformable models,
  such as Snakes and Gradient Vector Flow deformable models;
\item related work on applying statistical knowledge to the models,
\item usage of contour-fitting algorithms in the field of tracking.
\end{itemize}
\subsection{Two-dimensional \& Three-dimensional Models}
\label{sec:23m}
Many traditional segmentation methods are effected by the assumption that the
images studied in computer vision are usually self-contained, namely,
the information needed for a successful segmentation can be extracted
from the images. In 1980s, a paradigm named \textit{Active Vision}~\cite{aloimonos1988active} 
escaped this bind and pushed the vision process in a more goal-directed fashion. 
After that the \textit{Snakes} algorithm was proposed in a seminar work conducted 
by Kass~\cite{kass1988snakes}. The original paper, spawned many variations
and extensions including the use of Fourier parameterisation~\cite{scott1987alternative}, 
and incorporation of the topologically adaptable models~\cite{mcinerney1995topologically}.
A realization of the Snakes using B-splines was developed in~\cite{brigger2000b}. 
% In two dimensions, the Snakes have a variation named active shape
% model~\cite{cootes1995active}, which is a discrete version of this
% approach.
Gradient Vector Flow (GVF)~\cite{xu1998snakes} is an extension developed
based on a new type of external field. In~\cite{xu2000gradient}
authors are concerned with the convergence properties of deformable
models. In three dimensions, a good deal of research work has been
conducted on matching three-dimensional models, both on rigid
~\cite{harris1993tracking} and deformable~\cite{terzopoulos1991dynamic} shapes.
% \subsection{Applications}
% \label{sec:app}
% Model-based segmentation methods are widely used in the field of
% medical image processing. Besides the segmentation,
% dynamic models, such as the Snakes and its variations, are greatly used in application of object
% tracking. A real-time tracking system based on deformable models, such
% as the Snakes, is developed
% in~\cite{terzopoulos1992tracking}. It proved that the active shape and
% motion estimators are able to deal very effectively with the complex
% motions of nonrigid objects. Furthermore, the combination of active
% models and Kalman filter theory is also a popular approach to
% tracking, some work about this can be found
% in~\cite{schick1991simultaneous}. And last but not least,
% ~\cite{blake1998active} is a complete volume about the topics of
% geometric and probabilistic models  for shapes and their dynamics.
\subsection{Statistical Models}
\label{sec:sm}
% Pattern recognition theory is a general statistical framework which is
% important in the study of model-based approaches. This has started from the 1970s
% and 1980s when a new interpretation of image was proposed in the
% statistical community.  
Analyzing the model fitting in a probabilistic
context has two great advantages. Firstly, the ranges of shapes are defined by a
probability density function and secondly, we can make use of the vast number 
of tools that are available in e.g. pattern recognition field.

In~\cite{kelemen1999three} and~\cite{kelemen1999elastic}, an elegant
use of statistical models for the segmentation of medical images is
presented. The resulting segmentation system consists of building
statistical models and automatic segmentation of new image data
sets by restricting elastic deformation of models. The works
in~\cite{sclaroff2001deformable} and~\cite{liu1999deformable} also
exploit the prior knowledge in that the statistical shape models enforce the prior
probabilities on objects by approximating the latter with an energy function.  
In this paper, we assume that the shapes' priors have a Gaussian form in
shape-space. In the case of a norm-squared density over  quadratic spline space,
the prior is a Gaussian Markov Random Field (MRF)~\cite{blake1998active}, 
which is used widely  for modeling prior distributions for 
curves~\cite{storvik1994bayesian}.

Defining a prior distribution for shape is only a part of the
problem as prior knowledge only controls the feature interpretation in the
image and thus just approximates the contour of an observed object. In
order to snap to the exact shape of the object a likelihood function is required. In some
special cases, we can get a solution by maximizing the likelihood, but
usually it is intractable because there is no closed-form solution available. 
An indirect approach known as Iterative Reweighted Least Squares~\cite{bishop2006pattern} 
is used to find the parameters of the model.

% The CCD algorithm uses local statistics to evaluate a conditional distribution, 
% then the iterative Maximum a Posteriori Probability (MAP)~\cite{sorenson1980parameter} 
% estimate process is used to refine parameters instead of maximizing a complicated cost function. 
% Moreover, a blurred curve model is proposed as a efficient mean for iteratively optimizing. The algorithm
% can be used in object localization and object tracking. As an example
% of applications of the CCD approach, an efficient, robust and fully
% automatic real-time system for 3D object pose tracking in
% image sequences is presented in~\cite{panin2006fully}
% and~\cite{panin2006efficient}. MultiOcular Contracting Curve Density
% algorithm (MOCCD)~\cite{hahn2007tracking} is an extension of the CCD
% approach. In the paper, it is integrated into the tracking system of
% the human body. 
\subsection{Tracking and Optimization}
The CCD tracker is based on a fast real-time
variant of the CCD algorithm. It is used to fit a curve model to a
sequence of images, for example, video data, i.e. Generally,
neighboring 2-D slices of a sequnce of images consist of similar
information, The CCD tracker takes only a small set of chosen pixels
which are likely to reduce the uncertainty of the curve. Thus the
CCD tracker can real-timely cope with the large amount of data.
Both the Snakes and the CCD can be used to build naive tracking
systems. In contrast to other approaches such as Kalman Filter-based
tracking described in~\cite{brookner1998tracking} or the Conditional
Density Propagation~\cite{isard1998icondensation}, the CCD tracker
uses only the pixels sampled in the vicinity of the contour. This means that the CCD 
tracker requires low computational resources and suppresses large number
of false positives.

\todod{Below text shall probably go in Introduction section}
The optimization step is very important for the CCD approach. There are many methods to
deal with optimization, which can be grouped into global and local
optimizers. The latter one is used in the CCD approach and it works as follows: 
first, a smoothed objective function is obtained by fitting
the curve model to a large scale description. Then the window's size is
gradually reduced. During the process, many types of  numerical
optimization methods such as Conjugate Gradient Method~\cite{press2007numerical}, 
Newton-Raphson iterative optimization scheme~\cite{bishop2006pattern}, Gaussian-Newton~\cite{panin2006fully} and Levenberg-Marquardt
(LMM) algorithm~\cite{contourpanin2011}, Least Squares Support Vector
Machine (LS-SVM)~\cite{vapnik2000nature} can be used.

\section{System Architecture}
\label{sec:arch}
In this section we will briefly laid out the basic steps of the initial
CCD algorithm as presented by Hanek et al~\cite{hanek2004contracting}.
\begin{figure}[htb]
  \centering
  \includegraphics[width=\columnwidth]{images/flowchart.jpg}
  \caption{The flowchart of the basic steps of the CCD algorithm.}
  \label{fig:flowchart}
\end{figure}
The algorithm consists of four major steps which are sketched in Figure~\ref{fig:flowchart}:
\begin{enumerate}
\item \textbf{Initialization}: Given an input image $I$ as training data, we first choose an initial
  contour for an object which will be fitted or tracked, and
  initial values for the means and covariances ($P(\Phi)$). In addition, for most practical
  applications a pre-processing stage (e.g. smoothing) gets applied as well.
\item \textbf{Learning of local statistics}: 
  In the step of learning of local statistics for each pixel in the
  vicinity of the expected curve two sets of local statistics
  are computed, one set for each side of the curve. The local statistics are obtained from
  pixels that are close to the pixel on the contour and most likely lie
  on the corresponding side of the curve, according to the current
  estimate of the model parameters. The resulting local statistics
  represent an expectation of "what the two sides of the curve look
  like"~\cite{hanek2004contracting}, also known as likelihood ($P(I|\Phi)$).
\item \textbf{Refinement of model parameters}: The conditional distribution, namely
  the product of a prior distribution and the likelihood, is evaluated
  as the cost function. Then MAP estimate is executed to optimize the
  parameters and as a result a MAP value of model parameter vector and
  covariance will be generated in this step.
\item \textbf{Convergence}: Check for the convergence of the 
  log posterior probability function $\log{P(\Phi) P(I|\Phi)}$. 
  If the convergence criterion is not satisfied return to step 2.
\end{enumerate}
\todod{conclude}
\section{Contracting Curve Density Algorithm}
\label{sec:ccd_novelties}
\subsection{Logistic Sigmoid Function}
One of advantages of the
model-based approach is that we can restrict a task at hand to the ROI
which is
expected to reduce the computational cost. Hence, we first define
the region which contains pixels in the vicinity of the expected image
curve. Considering the complexity and the expense of computing, it is practicable
to choose those pixels that are actually required for interpolation along
normals of the curve (Fig.~\ref{fig:prior}). This is proved useful and important for image
perception and real-time tracking system. In the implementation of
this thesis, the processing is limited to a segment of each normal within
a search region. A fixed distance $h$ along the normal segment is
chosen according to the hypothetical uncertainty of the parametric curve. In the
special case of the norm-squared prior in spline space, a reasonable
search segment is determined as follows:

\begin{equation}
  \label{eq:radius}
  h = \sqrt{2} \rho_0 = \sqrt{\mathrm{tr}(\mathbf{\Sigma}_{\mathbf{\Phi}}\mathbf{A}^T\mathcal{U}\mathbf{A})}\qquad.
\end{equation}

$h$ denotes the size of a \textit{window} which is used for computing
the local statistics. In the beginning of the iterative procedure, the value
is relatively big and only roughly approximates the vicinity of the image curve
. The
uncertainty is reduced after further iteration steps and as a result, the $h$ becomes smaller and
smaller. After determining the length of the search segment, 
a set of points located on these segments can be collected and
evaluated. Note that the parametric model curve is not required to be
closed, but it shall always encompass a limited area. We only plan to
analyze the pixels located in the vicinity of the contour (red sample
pixels in Fig.~\ref{fig:prior}). Therefore,
we should pay attention to limit the search distance on the
\textit{inner} side in order to avoid crossing the opposite
boundary to sample pixels from the wrong area~\cite{panin2006fully}. In order to
decrease the computational expense, it is advisable to uniformly sample those
pixels on both segments in the vicinity of the contour. On the other
hand, we should avoid to collect too small number of pixels, because
it is statistically invalid and can not
capture all features (e.g. spinodals and corners) of the contour. Let us denote the
sample distance using $\Delta h$, then the overall number of spaced
sample points $L$ ($2L$ for both sides in all) can be given by:
\begin{equation}
  \label{eq:sample}
  L = \lfloor \frac{h}{\Delta h} \rfloor\qquad.
\end{equation}

Note that the goal of the algorithm is to assign each pixel
($\mathrm{v}_{k,l}, k \in [0,\ldots,N_{\mathrm{C}}-1], l \in [0,
2L-1]$) on either side of the contour. By doing so we thus run into a
classification problem.
Although each pixel should be assigned to one and only
one class so that the target variable is discrete, we can model the
posterior probabilities that lie in $(0,1)$ interval, which converts the classification into the regression problem. To achieve the latter, we model the probabilistic
assignments $\mathbf{a}_{v}$ for each pixel $\mathrm{v}_{k,l}$ as following:
\begin{equation}
  \label{eq:pa}
  \mathbf{a}_v  = (a_{v,1}, a_{v,2})^T\qquad,
\end{equation}
where $a_{v,1}$ describes to which extent a pixel $v$ is expected to
be influenced by side $1$ of the curve, and $a_{v,2}$ is equivalent
for side 2 given by $a_{v,2} = 1- a_{v,1}$. For arbitrary curve
$\mathbf{C}$, it is difficult to give a closed form of $a_v$. In the
following, an efficient approximation of the assignment is derived.

We will first evaluate the \textbf{signed} distance $d_{k,l}$ between pixel
$\mathrm{v}_{k,l}$ and a given curve $\mathbf{C}$
(Fig.~\ref{fig:dis}), which
can be approximated by:
\begin{equation}
  \label{eq:dis}
  d_{k,l} = \mathbf{n}_k \cdot ( \mathbf{v}_{k,l} - C_k)\qquad,
\end{equation}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{images/dis.jpg}
  \caption{The distance between a curve point and a pixel in the
    vicinity of a contour: $C_k$ is the curve point, $v_{k,l}$ is a
    pixel in the perpendicular of the contour, $d_{k,l}$ is the
    distance between $C_k$ and $v_{k,l}$.}
  \label{fig:dis}
\end{figure}

where $\mathbf{v}_{k,l} = {x_{k,l} \choose y_{k,l}}$ is the axis
components of a pixel
$\mathrm{v}_{k,l}$, and $C_k$ is the equivalent for point $C$ on the
curve given by ${x_k \choose y_k}$. Now consider that the curve is
distorted by a Gaussian $p(\mathbf{\Phi})$ which makes the displacement $d_{k,l}$ also Gaussian distributed: $p(d_{k,l}) \sim
\mathcal{N}(d_{k,l}|m_d, \sigma)$, where $m_d$ and $\sigma$ are mean
and covariance of the distribution. Covariance $\sigma$ is expressed as:
\begin{equation}
  \label{eq:cov}
  \sigma = \mathbf{n}_k \cdot \mathbf{J}_k \cdot \mathbf{\Sigma}_{\Phi}
  \cdot \mathbf{J}_k^T \cdot \mathbf{n}_k^T\qquad,
\end{equation}
where $\mathbf{J}_k$ is the Jacobian of curve $\mathbf{C}$. $\sigma$
can be taken as the uncertainty of the curve along the normal
introduced by the covariance
$\mathbf{\Sigma}_{\mathbf{\Phi}}$, it is a constant and can be
evaluated offline. The variable
$\frac{d_{k,l}}{\sigma}$ now becomes a linear function with respect to $\mathbf{\Phi}$.

In order to apply the probabilistic generative models to the
classification problem,
% calculate the the probability that a point lies on side 1 of the curve
we need to transform the linear function of $\mathbf{\Phi}$ using a
non-linear activation function $f(\cdot)$~\cite{bishop2006pattern}:
\begin{equation}
  \label{eq:nonla}
  a_{v,1} = f(\frac{d_{k,l}}{\sigma})\qquad.
\end{equation}
Currently, two main non-linear activation functions are mostly used
to solve the classification problem. The first is known as the
\textit{logistic sigmoid} function, and is given by:
\begin{equation}
  \label{eq:logistic}
  a_{v,1} =
  \frac{1}{1+\mathrm{exp}(\frac{d_{k,l}}{\sqrt{2}\sigma}))}\qquad .
\end{equation}
The term \textit{sigmoid} stands for
S-shaped~\cite{bishop2006pattern}. In~\cite{hanek2004contracting},
another activation function named probit is used, which is defined by:
\begin{equation}
  \label{eq:erf}
  a_{v,1} = \frac{1}{2}erf(\frac{d_{k,l}}{\sqrt{2}\sigma} + 1)\qquad ,
\end{equation}
where the error function of a Gaussian distribution is used. Both
two functions in Eq.~\ref{eq:erf} and Eq.~\ref{eq:logistic} are
S-shaped (Fig.~\ref{fig:s-shaped}).
\begin{figure} 
    \centering 
    \includegraphics[width=0.48\columnwidth]{images/logistic.jpg}
    \includegraphics[width=0.48\columnwidth]{images/erf.jpg}
    \caption{\textbf{Left:} Logistic
  sigmoid function, \textbf{Right:} probit function: Both functions
  are S-shaped}
\label{fig:s-shaped}
\end{figure}

In this thesis, we use both of them to implement the algorithm. They give
similar results but have different behaviors. Logistic sigmoid function
can be perfectly interpreted from the perspective of
probability. Consider the side $s \in \{0,1\}$, the posterior
distribution for side $s = 1$ can be written as:
\begin{eqnarray}
  \label{eq:pdfs}
  p(s=1|I) &=& \frac{p(I|s=1)p(s=1)}{p(I|s=1)p(s=1)
    + p(I|s=2)p(s=2)}\\
&=&  \frac{1}{1+exp(-\mathcal{R})}\qquad,
\end{eqnarray}
where I is pixels' RGB value, and $\mathcal{R}$ is defined as:
\begin{equation}
  \label{eq:ratio}
  \mathcal{R} = \frac{p(I|s=1)p(s=1)}{p(I|s=2)p(s=2)}\qquad.
\end{equation}
The logistic sigmoid plays an important role in many classification
algorithms. It satisfies the symmetry property, and its inverse 
is known as \textit{logit} function, which represents the log of the
ratio of probabilities $ln [p(s=1|I)/p(s=2|I)]$ for the two classes,
also known as the log odds~\cite{bishop2006pattern}.

The logistic sigmoid function can be used to transform a broad range
of class-conditional distributions, described by the exponential
family, to a non-linear posterior class probabilities. Since not all choices of
class-conditional density are trivial, the probit function is explored
to cope with other complex distributions. The results of logistic
sigmoid function and probit function tend to be similar, except that the
probit function is sensitive to outliers because the logistic sigmoid
decays asymptotically like $\mathrm{exp}(-x)$ for $x \rightarrow \infty$, whereas
for the probit activation function the decay is like
$\mathrm{exp}(-x^2)$ (Fig.~\ref{fig:outliers}).
\begin{figure} 
  \includegraphics[width=\columnwidth]{images/outliers.jpg}
\caption{Classification problem: The
  right plot shows the corresponding results obtained when outliers
  are added at the bottom left of the diagram, showing  that probit
  regression is highly sensitive to outliers, unlike logistic
  regression~\cite{bishop2006pattern}}
\label{fig:outliers}
\end{figure}
% Generally, we can call this approximation process as \textit{fuzzy} (or \textit{smooth})
% assignment. The accuracy of this assignment will increase as the
% uncertainty of curve governed by covariance $\mathbf{\Sigma}_{\mathrm{\Phi}}$ decreases.

With this assignment and following the suggested rule in~\cite{hanek2004contracting}, we now start to assign two suitable weighting functions
$\omega_1$, $\omega_2$ to the pixels $\mathrm{v}_{k,l}$ along the
normal for the two sides of the curve. the weighting functions are
defined as:

\begin{equation}
  \label{eq:weight}
  \omega_{1/2}(d_{k,l}) = C\left(\frac{a_{1/2}(d_{k,l}) -
    \gamma_1}{1-\gamma_2}\right)^4 \left[e^{-d_{k,l}/(2\hat{\sigma}^2)} - e^{-\gamma_2}\right]^+\qquad,
\end{equation}
where $\gamma_1$ equals to $0.5$ (disjoint weight assignment) and $\gamma_2$
equals to $4$ for the truncated Gaussian~\cite{hanek2004contracting}. 

\begin{figure} 
\includegraphics[width=0.48\columnwidth]{images/weight1.jpg}
\includegraphics[width=0.48\columnwidth]{images/weight2.jpg}
\caption{The weight functions of the two sides of the contour, a) the
  weight function along the positive direction (outside) in the normal of the
  contour. b) the weight function along the negative direction (inside). }
\label{fig:weight}
\end{figure}

In addition, the standard
deviation is chosen in order to cover the specified distance $h$,
which yields 
\begin{equation}
  \label{eq:deviation}
  \hat{\sigma} = \max \left[\frac{h}{\sqrt(2\gamma_2)}, \gamma_4
  \right], \sigma  = \frac{1}{\gamma_3} \hat{\sigma}\qquad,
\end{equation}

with the two additional constants $\gamma_3 = 6$ (linear dependence
between $\sigma$ and $\hat{\sigma}$) and $\gamma_4 = 4$ (minimum
weighting window width) as discussed in~\cite{panin2006efficient}. 

In the implementation of this thesis,
there are $2 \cdot L \cdot N_C$ distances, fuzzy assignments
and weight functions which leads to as many weight functions being evaluated offline and stored in an array. Now we have restricted our analysis region of interest in the
limited area, and collected all statistical information required to learn
local statistics. In the next part, we will evaluate the local
statistics.

\subsection{Curve Parametrization}
Optional....

By applying the (uniform quadratic or cubic) B-spline interpolation to the control points, a new curve
grouped by a sequence of equidistant distributed points is generated. 
The B-spline curve %is defined in eq.~\ref{eq:paramcurve} and 
is composed of a sequence of points $\mathbf{C} = \{C_0, \ldots,
C_{k}\}$, $k = N_{C-1}$. $N_C$ denotes the number of sample points in the
parametric curve. $N_C$ is significant for the
performance of the CCD algorithm, because its value is directly
proportional to the circumference of the observed object. For a high
resolution image, more sample points should be taken into account.
Hence, there is a trade-off between computational expense and the
accuracy. We recommend to compute the circumference of a given object before
determining $N_C$ and sample more points near spinodals and corners to
capture key features of the object.

Since the resulting parametric curve is continuous and
differentiable, we can easily compute the normal vector $\mathbf{n} = \{n_0, \ldots,
n_{k}\}$ and the tangent vector $\mathbf{t} = \{t_0, \ldots, t_{k}\}$.
% which was discussed in Section~\ref{sec:pbc}. 

In the planar affine shape-space $\mathcal{S}$, the contour, a
hypothetical initial estimate, can be compactly represented using a
vector $\mathbf{\Phi}$ with 6 real elements, namely model
parameter vector. From the perspective of probability, the hypothetical
curve gives a uncertainty, the solution of the curving problem is
therefore no longer just a single curve, but a whole family of
possible curves (Fig.~\ref{fig:transform}). The Gaussian probability density for these possible
curves in shape-space $\mathcal{S}$ is given as:

\begin{equation}
  \label{eq:prior}
   p(\mathbf{\Phi}) \propto
\mathrm{exp} \left\{ -\frac{1}{2} (\mathbf{\Phi} -
  \mathbf{m}_{\mathbf{\Phi}})^T \mathbf{\Sigma}_{\mathbf{\Phi}}^{-1} (\mathbf{\Phi} -
  \mathbf{m}_{\mathbf{\Phi}}) \right\}\qquad.
\end{equation}

\begin{figure}[htb]
  \centering
  \includegraphics[width=\columnwidth]{images/prior.jpg}
\caption{The top
  figure is the mean shape, the left one represents the euclidean
  similarities, the right one
  sketches some samples in affine space. All these are governed by a
  Gaussian distribution in shape-space with root-mean-square
  displacement of 0.3 length units.}
\label{fig:transform}
\end{figure}

In two dimensions, the current mean model parameter
$\mathbf{m}_{\mathbf{\Phi}}$ is a vector with $6$ elements, and current
covariance matrix $\mathbf{\Sigma}_{\mathbf{\Phi}}$ is a $6 \times 6$ matrix, which measures the variability of
how much two groups of model parameters change together. The
information matrix $\mathbf{\Sigma}_{\mathbf{\Phi}}^{-1}$ can be
written as:
\begin{equation}
  \label{eq:infomatrix}
  \mathbf{\Sigma}_{\mathbf{\Phi}}^{-1} = \frac{N_{\mathbf{\Phi}}}{\rho_0^2} \mathbf{A}^T\mathcal{U}\mathbf{A}\qquad,
\end{equation}
where $\rho_0^2$ denotes the mean-square displacement along the entire
curve (\cite{blake1998active}). $\mathbf{A}$ is the shape-matrix, and $\mathcal{U}$ is
metric matrix for curves. $N_{\mathbf{\Phi}}$ represents
the number of model parameters. Note $\rho_0^2$
is a real value and can be computed easily as:
\begin{equation}
  \label{eq:trace}
  \rho_0^2 = \mathrm{tr}(\mathbf{\Sigma}_{\mathbf{\Phi}})\qquad,
\end{equation}
where $\mathrm{tr}(\cdot)$ operation denotes the trace of a matrix.

The pre-processed input images and the parametric curve model have
thus been set up. In the following sections, the iterative procedure of the
CCD algorithm will be described in detail.

\subsection{Automatic Initialization Modes}

After the pre-processing of input images,  we initialize the model contour. For the moment, we only consider two-dimensional
affine shape-space consisting of 6 DOFs. % It is followed by the process of
% model parametrization.

In our implementation, we model the
contour as a continuous, differentiable and uniform quadratic or cubic
B-Spline in $\mathbb{R}^2$.
% which was discussed in Chapter~\ref{chapter:bspline}. 
Given a ROI (region of interest), the first step is to generate
sufficient control points $\mathbf{P} = \{P_0, \ldots, P_{N_p-1}\}$ to
account for the complexity of the object shape (Fig.~\ref{fig:prior}).

\begin{figure}[htb]
  \centering
  \includegraphics[width=\columnwidth]{images/cont.jpg}
\caption{A contour with sample points used for learning local statistics. The blue contour
  divided the image into two parts: outside and inside. As depicted in
  right-bottom image, pixels inside the contour are labeled "0",
  and those outside the contour are labeled "1". For each point on the
  contour (the skyblue point), we sample some points (red points) along both positive
  and negative direction.}
\label{fig:prior}
\end{figure}

There are two ways to generate control points:
manual initialization and automated initialization. 
Since the former is rather tedious, two new
intelligent initialization methods are proposed to extract the
contour. Firstly, an initial contour estimation method is described and
implemented by employing the well-known Scale-Invariant Feature Transform 
(SIFT) algorithm~\cite{lowe2004distinctive} for
keypoint detection and matching. Secondly, we make use of the a priori
modeled meshes of deformable objects (such as T-Shirts), extract their
concave contours and use projections of those as an initial guess. Both 
methods are shortly discussed below.

\subsubsection{SIFT-based Initialization}
\label{sec:sift}
We use the SIFT algorithm to initialize the
contour of an object. Assume we have marked the boundary points in the
training images. In order to project these boundary points to the test
image, it is essential to estimate the homography between the
images. However, SIFT matching might lead to lots of "false" matches.
For filtering out false positives, we use RANSAC~\cite{fischler1981random}, 
which is an iterative process that randomly selects enough matches to fit the
homography.

The whole algorithm amounts to the following steps: 


\begin{itemize}
\item  Randomly select a sample of matched points and instantiate the
  model from this subset.
\item Determine the set of data points that are within a distance
  threshold of the homography. The set is the consensus set of the sample
  and defines the inliers.
\item If the size of the set (e.g. the number of inliers) is greater
  than some threshold, re-estimate the homography using all the matched
  points and terminate. Otherwise, select a new subset and repeat the
  above.
\item After some trials the largest consensus set is selected, and the
  homography is re-estimated using all the points in the subset.
\end{itemize}
Fast way to compute the homography in a least squares sense is to use the Normalized
Direct Linear Transform (normalized
DLT ~\cite{hartley2003multiple}. The Normalized DLT algorithm computes
a homography for a projective transformation by using at least 4 point
correspondences and then minimizing corresponding norm.

After obtaining the homography between the template image and the
test image, the contour of object can be easily projected
into the test image to obtain the estimate of the contour
position. This is illustrated in Fig.~\ref{fig:sift_result}. Note that because SIFT is only invariant
to minor changes in view points, the method does not always work for
three-dimensional objects which have substantially different view points.

\subsubsection{Mesh Model-based Initialization}
\label{sec:pcl}
\todod{}


% ALTERNATIVE:
% The robot generates object hypotheses by detecting candidate point clusters in
% the three-dimensional point cloud acquired by the depth sensor. 
% The identified point clusters in the
% point cloud are then back-projected into the captured image
% to form the region of interest that corresponds to the object
% candidate. An accurate back-projection is possible thanks to
% the accurate robot calibration. The sensors are calibrated using a non-linear bundle-
% adjustment-like optimization to estimate various parameters
% of the PR2 Robot. However,
% the resulting polygons of the observed object are not smoothed,
% usually it can not completely encompass the whole object.
% By applying the CCD algorithm, we can accurately obtain the contour of
% a observed object. 

\section{Applications and Experimental Results}
\label{sec:results}
\todo{
\begin{enumerate}
\item initialization parameters
\item time to converge
\item if you run it multiple times also the number of False Positives (number of times it did not converge).
\end{enumerate}
}

\todos{Describe in 1 or 2 sentences how the test has been done (how
  many objects, how many runs}
\dones{start}
In this experiment (manual initialization), a partial occluded book
is put in a clutter. The initial contour is manually drawn. With a
given parameters, if the initial contour successfully snaps to the
edge of the book, the CCD algorithm successfully recognizes the book,
otherwise failure. For the test image, we run the CCD algorithm with
40 different positions, two times are failure cases because of wrong
initialization, the average run-time is 3.35s.

In the second experiments (sift initialization),  the initial contour
is generated by features matching based on SIFT. We run the CCD
algorithm 100 times and 9 failures happened because the SIFT did not
find appropriate initial contour. 

The third one (obselete)

failure rate is the ration of failures cases and all test cases. It
indicates the robustness of the CCD algorithm. run time is the average
run time of all successful test cases, which characterizes the
computational cost. The tolerance is the converge criteria, in our
experiments, we use the curve-displacement (as depicted in my thesis)
between two successive iterations as the tolerance.
\dones{end}
\subsection{Manual Initialization}
\begin{figure}[htbp]
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 1]{\includegraphics[width=1.5in]{experiments/book/0.png}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 5 ]{\includegraphics[width=1.5in]{experiments/book/4.png}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 10]{\includegraphics[width=1.5in]{experiments/book/9.png}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 20]{\includegraphics[width=1.5in]{experiments/book/19.png}}
  \end{minipage} 
  \caption{Segmentation of a book after manual initialization of the contour.}
  \label{fig:book}
\end{figure}

\subsection{SIFT-based Initialization}
\label{sec:sift_init}
\begin{figure}[htbp]
  \centering
\includegraphics[width=6cm]{experiments/book_sift/stacked.jpg}
  \caption{Segmentation of a book after SIFT-based initialization of the contour.}
  \label{fig:book}
\label{fig:sift_result}
\caption[Contour initialization using the SIFT algorithm]{The image in
  the upper-left corner is a template. It is projected into the bottom
  image. The green points in the template image encompass the
  contour of the observed object. The red lines are used to connect the matching feature
  points. Obviously, the outliers are excluded using the RANSAC
  algorithm. The homography is then estimated from these matching
  feature points.  After finding a perspective
  transformation from the matching features, the source contour is
  projected onto the image in the bottom, and used as initial contour
  for the CCD algorithm.}
\end{figure}

\subsection{Model-based Initialization}
\label{sec:tifpc}
\begin{figure}[htb]
  \centering
  \includegraphics[width=6cm]{experiments/tshirt/tshirt_pcd.jpg}
\end{figure}

\begin{figure}[htbp]
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 1]{\includegraphics[width=1.5in]{experiments/tshirt/0.png}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 5 ]{\includegraphics[width=1.5in]{experiments/tshirt/4.png}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 10]{\includegraphics[width=1.5in]{experiments/tshirt/9.png}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 28]{\includegraphics[width=1.5in]{experiments/tshirt/27.png}}
  \end{minipage} 
  \caption[Manual Initialization]{T-Shirt}
  \label{fig:book}
\end{figure}

\subsection{CCD-based tracker}

\begin{figure}[htbp]
  \begin{minipage}[t]{0.49\linewidth} 
    \centering  
    \subfloat[Sampled frame 1]{\includegraphics[width=1.5in]{images/sift/1.jpg}}    
  \end{minipage}% 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[Sampled frame 2]{\includegraphics[width=1.5in]{images/sift/10.jpg}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[Sampled frame 3]{\includegraphics[width=1.5in]{images/sift/30.jpg}}
    \label{subfig:iteration 3}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[Sampled frame 4]{\includegraphics[width=1.5in]{images/sift/45.jpg}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[Sampled frame 5]{\includegraphics[width=1.5in]{images/sift/63.jpg}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[Sampled frame 6]{\includegraphics[width=1.5in]{images/sift/80.jpg}}
  \end{minipage} 
  \caption[The tracking result based on SIFT contour initialization]{The
    CCD tracker successfully tracks the motion of a book.
  }
  \label{fig:sifttracker}
\end{figure}

\subsection{Quantization Results }
\label{sec:qantization}
\begin{table}[htbp]
\label{tab:qr}
\centering
\resizebox{0.49\textwidth}{!}{\begin{tabular}{|l|c|c|c|c|}
\hline
experiments & failure rate& run time & iteration & tolerance\\
\hline
manual initialization& 5\% & 3.35 & 26 & 0.001\\
\hline
sift initialization & 9\% & 3.52 & 5 & 0.001\\
\hline
model-based & 4\% & 10.15 & 28 & 0.001\\
\hline
\end{tabular}}
\caption{Quantization Results}
\end{table}
\dones{tolerance means the convergence criteria}

\begin{table}[htbp]
\label{tab:ip}
\large
\centering
\resizebox{0.49\textwidth}{!}{\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
experiments & $\gamma_1$& $\gamma_2$ & $\gamma_3$& $\gamma_4$ & $\alpha$
& $\kappa$ & $c$ & $h$ & $\Delta h$ &samples& degrees &dims\\
\hline
manual & 0.5 & 5 & 7 & 5 & 1.2 & 0.5 &0.25 &40 &2 & 60 & 4 & 6\\
\hline
sift  & 0.5 & 5 & 7 & 5 & 1.2 & 0.5 &0.25 &48 &1 & 80 & 4 & 6\\
\hline
model & 0.5 & 5 & 7 & 5 & 1.2 & 0.5 &0.25 &50 &1 & 200 & 4 & 6\\
\hline
\end{tabular}}
\caption{initialization parameters}
\end{table}
\dones{these parameters are explained in Section CCD}



\section{Conclusions and Future Work}
\label{sec:conclusions}
\section*{Acknowledgment}
 This work was supported by the DFG cluster of excellence \emph{CoTeSys} (Cognition for Technical Systems).
\bibliographystyle{IEEEtran}
\bibliography{references}
\end{document}
