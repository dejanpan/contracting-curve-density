\documentclass[conference]{IEEEtran}
% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi

\usepackage{cite}
\usepackage{times}
\usepackage{wrapfig}
% \usepackage{tweaklist}
\usepackage{xspace}
\usepackage{graphicx}
\usepackage[version=latest]{pgf}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage{bm}
\usepackage{color}
\usepackage{colortbl}
\usepackage{subfig}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{tikz}
\usetikzlibrary{%
  arrows,%
  calc,%
  fit,%
  patterns,%
  plotmarks,%
  shapes.geometric,%
  shapes.misc,%
  shapes.symbols,%
  shapes.arrows,%
  shapes.callouts,%
  shapes.multipart,%
  shapes.gates.logic.US,%
  shapes.gates.logic.IEC,%
  er,%
  automata,%
  backgrounds,%
  chains,%
  topaths,%
  trees,%
  petri,%
  mindmap,%
  matrix,%
  calendar,%
  folding,%
  fadings,%
  through,%
  positioning,%
  scopes,%
  decorations.fractals,%
  decorations.shapes,%
  decorations.text,%
  decorations.pathmorphing,%
  decorations.pathreplacing,%
  decorations.footprints,%
  decorations.markings,%
  shadows}
% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\graphicspath{{paper_figures/}}

\newcommand{\todo}[1]{\textbf{\textcolor{red}{TODO: #1}}}
\newcommand{\todos}[1]{\textbf{\textcolor{red}{TODO Shulei: #1}}}
\newcommand{\todod}[1]{\textbf{\textcolor{red}{TODO Dejan: #1}}}
\newcommand{\dones}[1]{\textbf{\textcolor{blue}{DONE Shulei: #1}}}
\newcommand{\review}[1]{\textbf{\textcolor{cyan}{#1}}}
 \setlength{\abovecaptionskip}{1ex}
 \setlength{\belowcaptionskip}{1ex}
 \setlength{\floatsep}{1ex}
 \setlength{\textfloatsep}{1ex}
\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Contracting Curve Density Algorithm for Applications in Personal Robotics}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Shulei Zhu and Dejan Pangercic and Michael Beetz}
\IEEEauthorblockA{Intelligent Autonomous Systems Group, TU Munich \\
Email: \{shulei.zhu, pangercic, beetz\}@cs.tum.edu}
}

% make the title area
\maketitle

\begin{abstract}
This paper investigates an extended and optimized
implementation of the state-of-the-art local curve fitting algorithm
named Contracting Curve Density (CCD) algorithm, originally developed 
by Hanek et al. In particular, we investigate its application  
in the field of personal robotics for the tasks such as the mobile
manipulation which requires a segmentation
of objects in clutter and the tracking of them. 
The developed system mainly consists of the two functional parts, the CCD
algorithm to fit the model curve in still images and the CCD tracker to
track the model in the videos. We demonstrate algorithm's working 
in various scenes using handheld camera and the cameras from the 
Personal Robot 2 (PR2). Achieved results show that the CCD algorithm achieves 
robustness and sub-pixel accuracy even in the presence of clutter, 
partial occlusion, and changes of illumination.
\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}
The CCD algorithm can be best described as follows. Given one or multiple images as input
data and a parametric curve model with a priori distribution of model
parameters, through curve-fitting process, we estimate the model
parameters which determine the approximation of the posterior
distribution in order to make the curve models best matching the image 
data~\cite{hanek2004contracting}.

The curve-fitting problem and its variants have a wide range of
applications in the field of robotics, medical processing, user
interface, surveillance and biometrics~\cite{hanek2004fitting}. In order to be
widely applicable to practical personal robotics problems (such as
perception of mobile manipulation), robustness,
accuracy, efficiency and versatility should be
considered when a novel approach is designed and implemented.
However, solving object segmentation and the
related object contour tracking problems are always challenging,
especially in natural and unconstrained scenes. Due to clutter,
shading, texture, and specular reflections it is very difficult to segment
an object from an inhomogeneous background. Furthermore, physical
conditions, such as the illumination or surface properties, will
influence the efficiency and stability of related approaches. 
We thus aim to introduce the substantial improvements to the original
version of CCD algorithm which adaptively learns background and 
foregorund models and leverages from other techniques such as
SIFT features matching or back-projection of point clouds (Fig.~\ref{fig:divide}) 
onto the test image to robustly segment the target objects.

\begin{figure}[htbp]
  \centering
  % \includegraphics[width=\columnwidth]{images/divide1.jpg}\\
  \includegraphics[width=\columnwidth]{teaser.jpg}
  \caption{Personal Robot 2 (PR2~\cite{Wyrobek08PR1}) robot segmenting the book using CCD algorithm. 
    The initial contour of of the book was generated through a 3D-based cluster segmentation
    and back-projection of the bounding box onto the test image.
    \textbf{Bottom-right:} Segmentation of a plate in a rather
  challenging scene.}
  \label{fig:divide}
\end{figure}

\subsection{An Alternative View of the CCD Algorithm}
\label{sec:overview}
In the field of pattern recognition, the key concept is that of
uncertainty. In image data, the uncertainty arises both
through noise from measurements, as well as through the nature of
the objects (e.g. cardiac motion and deformation). Probability theory
provides a consistent framework for the quantification and
manipulation of uncertainty.  In this section, we consider curve-fitting
problem from a probabilistic perspective and turn it into
a classification problem.

In the CCD algorithm, the aim is to find the contour of observed object
and thus segment it from the background. Therefore, a hypothetical 
contour divides the image into two parts (Fig.~\ref{fig:prior}), inside
and outside. For probabilistic model, we can represent this using
binary representation (e.g. $\{0, 1\}$). The goal of the CCD algorithm
then becomes to accurately assign a class label to each pixel in the vicinity of the
contour and the curve-fitting problem thus becomes a classification
one. A powerful approach to solve this problem involves modeling of a
conditional probability distribution in an inference stage, and then
subsequently using this distribution to make optimal decisions. In
order to derive the conditional probability, prior distribution and
likelihood function should be given.

We assume that a parametric curve model is governed by a prior distribution
over the model parameters (usually a multi-dimensional vector). There
exists a range of probability distributions which can be used to model
the distribution of shapes. In this paper we consider the Gaussian distribution.

% Defining the prior distribution is only a step of the problem.
% According to the Bayesian theorem, the conditional distribution
% is proportional to the product of prior distribution and the likelihood
% function. Hence, the next step is to define the likelihood function.
In the implementation of the CCD algorithm local image pixel values are used
as the training data to determine the likelihood function. If the data is 
assumed to be drawn independently from the distribution, then the likelihood 
function is given by the accumulation of all the components.
By pixel value we denote the vector containing the local single- or multichannel
image data associated to a pixel (e.g. RGB values). 
However, other types of local features computed in a pre-processing
step may also be used, e.g. texture descriptors or color values in
other color spaces. The likelihood function obtained from the local statistics does
not have a closed-form solution. In addition, the prior distribution is just
an approximate to the true distribution. Since the maximization
likelihood method was proven \cite{bishop2006pattern} not to work here, we have to use an alternative
approach known as Iterative Reweighted Least Squares (IRLS) to find
the solution. Here the IRLS process is used to find the Maximum a Posterior (MAP)
estimate.

In the CCD algorithm, because we just need a parameter vector determining
the shape of the specified contour, we do not plan to calculate the
predictive distribution. Therefore, the MAP solution mentioned above
becomes our final objective function.

% An important and decisive issue to consider is the fact that the exact inference for the
% regression is always intractable. In the next sub-section we will discuss how we
% solved this problem yet even improved the robustness and performance. 

\subsection{Key Contributions}
In order to improve the stability, accuracy and robustness over the original
implementation we introduce the following novel improvements. Firstly, we use 
the logistic sigmoid function instead of a Gaussian error function which renders a
curve-fitting problem as a Gaussian logistic problem~\footnote{For the two-class
classification problem, the posterior probability 
of class $C$ can be written as a \textbf{continuous} logistic sigmoid acting
on a linear function of $x$ (equivalent to \textit{fuzzy assignment}).} known in the field of pattern 
recognition. Secondly, a quadratic or
a cubic B-spline curve is used to model the parametric curve
to avoid the Runge phenomenon~\cite{süli2003introduction} without increasing the degree of the
B-spline. Thirdly, the system supports both planar affine (6-DOF) and
three-dimensional affine (8-DOF) shape-space. The latter affine space can avoid
curve mismatching caused by major viewpoint changes. Lastly, in
order to avoid manual intervention by the user, the developed system
also supports robust global initial curve initialization modules based on both keypoint
feature matching and projection of concave contours a priori designed mesh models.
The herein presented work is implemented as part of ROS and freely 
available on \url{www.ros.org}~\footnote{\url{http://www.ros.org/wiki/contracting_curve_density_algorithm}}.

In the remainder of this paper we first introduce the related approaches, 
in Section~\ref{sec:arch} we then shortly revisit an original implementation of 
CCD algorithm and continue with a presentation of our improvements over the
original idea (Section~\ref{sec:ccd_novelties}). In Section~\ref{sec:results}
we present the set of possible applications for CCD and evaluation of thereof and
conclude with Section~\ref{sec:conclusions}.

\section{Related Work}
\label{sec:rw}
We will split this section based on the following two criteria:
\begin{itemize}
\item related work on two-dimensional and three-dimensional deformable models;
\item related work on applying statistical knowledge to the models.
%\item usage of contour-fitting algorithms in the field of tracking.
\end{itemize}
\subsection{Two-dimensional \& Three-dimensional Models}
\label{sec:23m}
Many traditional segmentation methods are effected by the assumption that the
images studied in computer vision are usually self-contained, namely,
the information needed for a successful segmentation can be extracted
from the images. In the real world, however, segmentation problems often require much
information external to the image. In 1980s, a paradigm named \textit{Active Vision}~\cite{aloimonos1988active} 
escaped this bind and pushed the vision process in a more goal-directed fashion. 
After that the \textit{Snakes} algorithm was proposed in a seminar work conducted 
by Kass~\cite{kass1988snakes}. % The original paper, spawned many variations
% and extensions including the use of Fourier parametrization~\cite{scott1987alternative}, 
% and incorporation of the topologically adaptable models~\cite{mcinerney1995topologically}.
A realization of the Snakes using B-splines was developed
in~\cite{brigger2000b}. In two dimensions, the Snakes have a variation named active shape
model~\cite{cootes1995active}, which is a discrete version of this
approach.
%% In the last two decades ``active contour'' or
%% ``snake'' has been developed as an effective interactive image segmentation tool
%% in a wide range of applications. In addition, drawing a box around an intended
%% segmentation target is another popular interaction paradigm considered
%% by many image segmentation frameworks
%% (e.g.,~\cite{lempitsky2009image,gradysegmentation,santner2011interactive}).

Gradient Vector Flow (GVF)~\cite{xu1998snakes} is an extension developed
based on a new type of external field. In~\cite{xu2000gradient}
authors are concerned with the convergence properties of deformable
models. In three dimensions, a good deal of research work has been
conducted on matching three-dimensional models, both on rigid
~\cite{harris1993tracking} and deformable~\cite{terzopoulos1991dynamic} shapes.
% \subsection{Applications}
% \label{sec:app}
% Model-based segmentation methods are widely used in the field of
% medical image processing. Besides the segmentation,
% dynamic models, such as the Snakes and its variations, are greatly used in application of object
% tracking. A real-time tracking system based on deformable models, such
% as the Snakes, is developed
% in~\cite{terzopoulos1992tracking}. It proved that the active shape and
% motion estimators are able to deal very effectively with the complex
% motions of nonrigid objects. Furthermore, the combination of active
% models and Kalman filter theory is also a popular approach to
% tracking, some work about this can be found
% in~\cite{schick1991simultaneous}. And last but not least,
% ~\cite{blake1998active} is a complete volume about the topics of
% geometric and probabilistic models  for shapes and their dynamics.
\subsection{Statistical Models}
\label{sec:sm}
% Pattern recognition theory is a general statistical framework which is
% important in the study of model-based approaches. This has started from the 1970s
% and 1980s when a new interpretation of image was proposed in the
% statistical community.  
Analyzing the model fitting in a probabilistic
context has two great advantages. Firstly, the ranges of shapes are defined by a
probability density function and secondly, we can make use of the vast number 
of tools that are available in e.g. pattern recognition field.

In~\cite{kelemen1999three} and~\cite{kelemen1999elastic}, an elegant
use of statistical models for the segmentation of medical images is
presented. The resulting segmentation system consists of building
statistical models and automatic segmentation of new image data
sets by restricting elastic deformation of models. The works
in~\cite{sclaroff2001deformable} and~\cite{liu1999deformable} also
exploit the prior knowledge in that the statistical shape models enforce the prior
probabilities on objects by approximating the latter with an energy function.  
In this paper, we assume that the shapes' priors have a Gaussian form in
shape-space. In the case of a norm-squared density over  quadratic spline space,
the prior is a Gaussian Markov Random Field (MRF)~\cite{blake1998active}, 
which is used widely  for modeling prior distributions for 
curves~\cite{storvik1994bayesian}. In contrast to the  MRF-based
approaches, ~\cite{gocmo2011} proposed a novel
framework for for a general multilabel regularizer allowing to model
certain shape priors based on the viewpoint of spatially continuous
optimization.

Defining a prior distribution for shape is only a part of the
problem as prior knowledge only controls the feature interpretation in the
image and thus just approximates the contour of an observed object. In
order to snap to the exact shape of the object a likelihood function is required. In some
special cases, we can get a solution by maximizing the likelihood, but
usually it is intractable because there is no closed-form solution available. 
An indirect approach known as Iterative Reweighted Least Squares~\cite{munk2006convergence} 
is used to find the parameters of the model.

% The CCD algorithm uses local statistics to evaluate a conditional distribution, 
% then the iterative Maximum a Posteriori Probability (MAP)~\cite{sorenson1980parameter} 
% estimate process is used to refine parameters instead of maximizing a complicated cost function. 
% Moreover, a blurred curve model is proposed as a efficient mean for iteratively optimizing. The algorithm
% can be used in object localization and object tracking. As an example
% of applications of the CCD approach, an efficient, robust and fully
% automatic real-time system for 3D object pose tracking in
% image sequences is presented in~\cite{panin2006fully}
% and~\cite{panin2006efficient}. MultiOcular Contracting Curve Density
% algorithm (MOCCD)~\cite{hahn2007tracking} is an extension of the CCD
% approach. In the paper, it is integrated into the tracking system of
% the human body. 
% \subsection{Tracking and Optimization}
% The CCD tracker is based on a fast real-time
% variant of the CCD algorithm. It is used to fit a curve model to a
% sequence of images, for example, video data, i.e. Generally,
% neighboring 2-D slices of a sequnce of images consist of similar
% information, The CCD tracker takes only a small set of chosen pixels
% which are likely to reduce the uncertainty of the curve. Thus the
% CCD tracker can real-timely cope with the large amount of data.
% Both the Snakes and the CCD can be used to build naive tracking
% systems. In contrast to other approaches such as Kalman Filter-based
% tracking described in~\cite{brookner1998tracking} or the Conditional
% Density Propagation~\cite{isard1998icondensation}, the CCD tracker
% uses only the pixels sampled in the vicinity of the contour. This means that the CCD 
% tracker requires low computational resources and suppresses large number
% of false positives.

% \todod{Below text shall probably go in Introduction section}
% The optimization step is very important for the CCD approach. There are many methods to
% deal with optimization, which can be grouped into global and local
% optimizers. The latter one is used in the CCD approach and it works as follows: 
% first, a smoothed objective function is obtained by fitting
% the curve model to a large scale description. Then the window's size is
% gradually reduced. During the process, many types of  numerical
% optimization methods such as Conjugate Gradient Method~\cite{press2007numerical}, 
% Newton-Raphson iterative optimization scheme~\cite{bishop2006pattern}, Gaussian-Newton~\cite{panin2006fully} and Levenberg-Marquardt
% (LMM) algorithm~\cite{contourpanin2011}, Least Squares Support Vector
% Machine (LS-SVM)~\cite{vapnik2000nature} can be used.

\section{System Architecture}
\label{sec:arch}
In this section we will briefly laid out the basic steps of the initial
CCD algorithm as presented by Hanek et al~\cite{hanek2004contracting}.
\begin{figure}[htb]
  \centering
  % \includegraphics[width=\columnwidth]{flowchart.jpg}
\begin{tikzpicture}
[auto,
decision/.style={diamond, draw=blue, thick, fill=gray!60,
text width=5em, text badly centered,
inner sep=1pt, scale=0.5},
block1/.style ={rectangle, draw=blue, thick, fill=blue!20,
text width=6em, text centered, rounded corners,
minimum height=5em, scale=0.5},
block2/.style ={rectangle, draw=blue, thick, fill=red!60,
text width=6em, text centered, rounded corners,
minimum height=5em, scale=0.5},
block3/.style ={rectangle, draw=blue, thick, fill=yellow!80,
text width=6em, text centered, rounded corners,
minimum height=5em, scale=0.5},
block5/.style ={rectangle, draw=blue, thick, fill=green!50,
text width=6em, text centered, rounded corners,
minimum height=5em, scale=0.5},
line/.style ={draw, thick, -latex',shorten >=2pt},
cloud/.style ={draw=red, thick, ellipse,fill=pink!50,
minimum height=2em,text centered}]
\matrix [column sep=5mm,row sep=7mm]
{
% row 1
 &
\node [block1] (init) {initialize model curves: $\mathbf{\Phi}$}; &
\node [block1] (rawdata) {input image: $\mathbf{I}$};
\\
% row 2
 & \node [block2] (identify) {identify prior probability: $p(\mathbf{\Phi})$}; 
& \node [block2] (evaluate) {evaluate local statistics: $p(\mathbf{I}|\mathbf{\Phi})$};\\
% row 3
\node [block3] (refine) {refine parameters}; &\node [block3] (map) {MAP estimate: $p(\mathbf{\Phi}|\mathbf{I})$}; &  \\
% row 4
& \node [decision] (decide) {test of convergence}; & \node [cloud] (irls) {IRLS};\\
% row 5
& \node [block5] (stop) {output parameters: $\mathbf{\Sigma}$, $\mathbf{\Phi}$ }; & \\
};
\begin{scope}[every path/.style=line]
\path (init) -- (identify);
\path (init) -- (rawdata);
\path (rawdata) -- (evaluate);
\path (evaluate) |- (map);
\path (identify) -- (map);
\path (map) -- (decide);
\path (refine) |- (init);
\path (decide) -| node [near start] {no} (refine);
\path (decide) -- node [midway] {yes} (stop);
\path [dashed] (irls) -- (map);
\end{scope}
\end{tikzpicture}

  \caption{The flowchart of the basic steps of the CCD algorithm.}
  \label{fig:flowchart}
\end{figure}
The algorithm consists of four major steps which are also sketched in Fig.~\ref{fig:flowchart}:
\begin{enumerate}
\item \textbf{Initialization (Blue)}: Given an input image $\mathbf{I}$ as training data, we first choose an initial
  contour for an observed object, then model the contour using a
  parameter vector $\mathbf{\Phi}$. In addition, for most practical
  applications a pre-processing stage (e.g. smoothing) gets applied as well.
\item \textbf{Learning of local statistics (Red)}: 
  In the step of learning of local statistics for each pixel in the
  vicinity of the expected curve two sets of local statistics
  are computed, one set for each side of the curve. The local statistics are obtained from
  pixels that are close to the pixel on the contour and most likely lie
  on the corresponding side of the curve, according to the current
  estimate of the model parameters. The resulting local statistics
  represent an expectation of ``what the two sides of the curve look
  like"~\cite{hanek2004contracting}, also known as likelihood: $p(\mathbf{I}|\mathbf{\Phi})$.
\item \textbf{Refinement of model parameters (Yellow)}: The conditional distribution, namely
  the product of a prior distribution and the likelihood, is evaluated
  as the cost function. Then MAP estimate is executed to optimize the
  parameters and as a result a MAP value of model parameter vector and
  covariance will be generated in this step.
\item \textbf{Convergence (Gray)}: Check for the convergence of the 
  log posterior probability function $\ln{p(\mathbf{\Phi}) p(\mathbf{I}|\mathbf{\Phi})}$. 
  If the convergence criterion is not satisfied return to step 2.
\end{enumerate}

\section{Contracting Curve Density Algorithm for Personal Robotics}
\label{sec:ccd_novelties}
In this section, we describe all important underlying principles of the CCD
algorithm and its extensions that make it suitable for the use in personal robotics field.
After a thorough evaluation of the original implementation we identified the following three
issues which needed to be substantially improved in order to assure the robust performance
and automatic boostrapping: i) automatic initialization, ii) parametrization of curve models and
iii) learning of local statistics.

\subsection{Automatic Initialization Modes}
%After the pre-processing of input images,  we initialize the model contour. For the moment, we only consider two-dimensional
% affine shape-space consisting of 6 DOFs.  It is followed by the process of
% model parametrization.
In our implementation, we model the
contour as a continuous, differentiable and uniform quadratic or cubic
B-Spline in $\mathbb{R}^2$.
% which was discussed in Chapter~\ref{chapter:bspline}. 
Given a region of interest (ROI), the first step is to generate
enough control points $\mathbf{P} = \{P_0, \ldots, P_{N_p-1}\}$ to
account for the complexity of the object shape (Fig.~\ref{fig:prior}).

\begin{figure}[htb]
  \centering
  \includegraphics[width=\columnwidth]{cont.png}
\caption{A contour with sample points used for learning of local statistics. The blue contour
  divides the image into two parts: outside and inside. As depicted in
  right-bottom image, pixels inside the contour are labeled ``0",
  and those outside the contour are labeled ``1". For each point on the
  contour (the light-blue point), we sample points (red points) along both positive
  and negative direction of the normal of the contour point.}
\label{fig:prior}
\end{figure}

There are two ways to generate control points, manually and automatically. 
Since the former is rather tedious, the two new
initialization methods are proposed to extract the
contour. Firstly, an initial contour estimation method is described and
implemented by employing the well-known Scale-Invariant Feature Transform 
(SIFT) algorithm~\cite{lowe2004distinctive} for
keypoint detection and matching. Secondly, we make use of the a priori
modeled meshes of deformable objects (such as e.g. T-shirts from Fig.~\ref{fig:tshirt}), 
extract their concave contours and use projections of those as an initial guess. Both 
methods are discussed below.

\subsubsection{SIFT-based Initialization}
\label{sec:sift}
We first extract SIFT features in the test image and match them against the template
image using Nearest Neighbor Search. For filtering out of false positive matches and estimation
of the homography, we use RANdom SAmple Consensus (RANSAC)~\cite{fischler1981random}, 
which is an iterative process that randomly selects matches in the test image, 
back-projects them onto the template image and verifies the 
relative normalized difference in order to select the inliers.
  
%% In order to speed-up the homography computation we use the Normalized
%% Direct Linear Transform (normalized DLT~\cite{hartley2003multiple}). The Normalized DLT algorithm computes
%% a homography for a projective transformation by using at least 4 point
%% correspondences and then minimizing the corresponding norm.
After obtaining the homography between the template image and the
test image, the bounding box around the feature inliers of the object is projected
into the test image to obtain the estimate of the contour
position (Fig.~\ref{fig:sift_result}).
\subsubsection{Mesh Model-based Initialization}
\label{sec:pcl}
In this mode we use publicly available mesh models, such as the ones from the 
Google 3D Warehouse (see a mesh of the T-shirt in top row of Fig.~\ref{fig:tshirt}).
In order to generate the initial contour we first sample vertex points and convert
the meshes into point clouds. Next we compute the 3D concave hull of the resulting 
point cloud using a Delaunay Triangulation algorithm and thus obtain an approximate
object shape identifier. In order to account for multi-scale of images we build the 
pyramid of different hull sizes normalized between the $[1/2...1.0]$ of the image
width. Finally we project all contour sizes onto the test image and
check the convergence criterion. Fig.~\ref{fig:tshirt} depict a successful
segmentation of the T-shirt which enables the robot to detect the cloth article
and e.g. folds it. 
%% The introduction of prior distribution with a certain number of degrees of freedom
%% imposes constraints to the classification problem. On the one hand,
%% these constraints restrain the degrees of freedom of the whole curve,
%% which increases inflexibility but decreases computational cost. On the
%% other hand, the constraints can greatly avoid converging to
%% local minima, because local convergence must keep consistent with the
%% global behavior.
Except those extreme cases, e.g., fitting a circular
contour to a tiny ring (both inner and outer edges are ring shaped),
the CCD method always converges to the global minimum granted that
 the real contour of the observed object is similar to its
initial contour. %% With the prior distribution, According to the
%% Bayesian theorem, we need to define the likelihood function in the
%% following step.

\subsection{Curve Parametrization}
Given the control points, by applying the (uniform quadratic or
cubic) B-spline interpolation, a new curve
grouped by a sequence of equidistant distributed points is generated. 
The B-spline curve %is defined in eq.~\ref{eq:paramcurve} and 
is composed of a sequence of points $\mathbf{C} = \{C_0, \ldots,
C_{k}\}$, $k = N_{C-1}$. $N_C$ denotes the number of sample points in the
parametric curve. $N_C$ is significant for the
performance of the CCD algorithm, because its value is directly
proportional to the circumference of the observed object. For a high
resolution image, more sample points should be taken into account.
Hence, there is a trade-off between the computational expense and the
accuracy. Sampling more points near spinodals and corners is thus
crucial for the successful operation of the algorithm.

Since the resulting parametric curve is continuous and
differentiable, we can easily compute the normal vector $\mathbf{n} = \{n_0, \ldots,
n_{k}\}$ and the tangent vector $\mathbf{t} = \{t_0, \ldots, t_{k}\}$
for every contour points (see Fig.~\ref{fig:prior}).
% which was discussed in Section~\ref{sec:pbc}. 

In the planar affine shape-space $\mathcal{S}$, the contour can be compactly 
represented using a vector $\mathbf{\Phi}$ with 6 real elements, namely a model
parameter vector. In order to model the whole family of
possible curves (Fig.~\ref{fig:transform}) let us first
introduce a Gaussian Probability Density Function that is used for modeling 
of these possible curves in shape-space $\mathcal{S}$:
\begin{equation}
  \label{eq:prior}
   p(\mathbf{\Phi}) \propto
\mathrm{exp} \left\{ -\frac{1}{2} (\mathbf{\Phi} -
  \mathbf{m}_{\mathbf{\Phi}})^T \mathbf{\Sigma}_{\mathbf{\Phi}}^{-1} (\mathbf{\Phi} -
  \mathbf{m}_{\mathbf{\Phi}}) \right\}\qquad.
\end{equation}
\begin{figure}[htb]
  \centering
  \includegraphics[width=\columnwidth]{prior.jpg}
\caption{The top-row figure represents the mean shape curve, 
  the bottom-left figure represents the euclidean
  similarities and the bottom-right figure
  some samples in affine space. All these are governed by a
  Gaussian distribution in shape-space with root-mean-square
  displacement of 0.3 length units.}
\label{fig:transform}
\end{figure}

In two dimensions, the current mean model parameter
$\mathbf{m}_{\mathbf{\Phi}}$ is a vector with $6$ elements, and current
covariance matrix $\mathbf{\Sigma}_{\mathbf{\Phi}}$ is a $6 \times 6$ matrix, which measures the variability of
how much two groups of model parameters change together. The
information matrix $\mathbf{\Sigma}_{\mathbf{\Phi}}^{-1}$ can be
written as:
\begin{equation}
  \label{eq:infomatrix}
  \mathbf{\Sigma}_{\mathbf{\Phi}}^{-1} = \frac{N_{\mathbf{\Phi}}}{\rho_0^2} \mathbf{A}^T\mathcal{U}\mathbf{A}\qquad,
\end{equation}
where $\rho_0^2$ denotes the mean-square displacement along the entire
curve (\cite{blake1998active}). $\mathbf{A}$ is the shape-matrix, and $\mathcal{U}$ is
a metric matrix for curves. $N_{\mathbf{\Phi}}$ represents
the number of model parameters. Note that $\rho_0^2$
is a real value and can be computed as:
\begin{equation}
  \label{eq:trace}
  \rho_0^2 = \mathrm{tr}(\mathbf{\Sigma}_{\mathbf{\Phi}})\qquad,
\end{equation}
where $\mathrm{tr}(\cdot)$ operation denotes the trace of a matrix.

The parametric curve model using uniform quadratic or
cubic B-spline has thus been set up. In the following sub-section the
logistic sigmoid function for the purpose of the local statistics learning 
will be discussed.

\subsection{Learning of Local Statistics}
% One of advantages of the model-based segmentation is that we 
% can restrict a task at hand to the ROI which is expected to reduce 
% the computational cost. Hence, we first define the region which contains 
% pixels in the vicinity of the expected final curve. In the implementation of
% this work, the processing is limited to a segment of each normal within
% a search region. A fixed distance $h$ along the normal segment is
% chosen according to the hypothetical uncertainty of the parametric curve. In the
% special case of the norm-squared prior in spline space, a reasonable
% search segment is determined as follows:
In order to learn local statistics (raw RGB pixel values), we first have 
to define the search interval $h$ on both sides of the curve:
\begin{equation}
  \label{eq:radius}
  h = \sqrt{2} \rho_0 = \sqrt{\mathrm{tr}(\mathbf{\Sigma}_{\mathbf{\Phi}}\mathbf{A}^T\mathcal{U}\mathbf{A})}\qquad,
\end{equation}
where $h$ denotes the size of a \textit{window} which is used for computing
the local statistics. In the beginning of the iterative procedure, the value
is relatively big and only roughly approximates the vicinity of the image curve. The
uncertainty is reduced after further iteration steps and as a result, the $h$ becomes smaller and
smaller. After determining the length of the search segment, 
a set of points located on these segments can be collected and
evaluated. Note that the parametric model curve is not required to be
closed, but it shall always encompass a limited area. We only 
analyze the pixels located in the vicinity of the contour (red sample
pixels in Fig.~\ref{fig:prior}). Therefore, we should limit the search distance on the
\textit{inner} side in order to avoid crossing the opposite
boundary to sample pixels from the outer area~\cite{panin2006fully}.
However, the search distance must be long enough to cover the real
contour of the given object. Otherwise local statistics will be invalid. 
On the other hand we should
avoid collecting statistics from too few pixels, because
it is statistically invalid and we can not capture all features 
(e.g. spinodals and corners) of the contour. Let us denote the
sample distance as $\Delta h$, then the overall number of spaced
sample points $L$ ($2L$ for both sides) can be given by:
\begin{equation}
  \label{eq:sample}
  L = \lfloor \frac{h}{\Delta h} \rfloor\qquad.
\end{equation}
Note that the goal of the algorithm is to assign each pixel
($\mathrm{v}_{k,l}, k \in [0,\ldots,N_{\mathrm{C}}-1], l \in [0,
2L-1]$) on either side of the contour. By doing so we thus run into a
classification problem.
%% Although each pixel should be assigned to one and only
%% one class so that the target variable is discrete, we can model the
%% posterior probabilities that lie in $(0,1)$ interval, which converts the classification into the regression problem.
To achieve this, we model the probabilistic
assignments $\mathbf{a}_{v}$ for each pixel $\mathrm{v}_{k,l}$ as following:
\begin{equation}
  \label{eq:pa}
  \mathbf{a}_v  = (a_{v,1}, a_{v,2})^T\qquad,
\end{equation}
where $a_{v,1}$ describes to which extent a pixel $v$ is expected to
be influenced by side $1$ of the curve, and $a_{v,2}$ is equivalent
for side 2 given by $a_{v,2} = 1- a_{v,1}$. 
% Since for arbitrary curve
% $\mathbf{C}$, it is difficult to find a closed form of $a_v$, we present
% an efficient approximation of the assignment in the following.

% We will first evaluate the \textbf{signed} distance $d_{k,l}$ between pixel
% $\mathrm{v}_{k,l}$ and a given curve $\mathbf{C}$
% (Fig.~\ref{fig:dis}), which
% can be approximated by:
% \begin{equation}
%   \label{eq:dis}
%   d_{k,l} = \mathbf{n}_k \cdot ( \mathbf{v}_{k,l} - C_k)\qquad,
% \end{equation}

% \begin{figure}[htbp]
%   \centering
%   \includegraphics[width=\columnwidth]{images/dis.jpg}
%   \caption{The distance between a curve point and a pixel in the
%     vicinity of a contour: $C_k$ is the curve point, $v_{k,l}$ is a
%     pixel in the perpendicular of the contour, $d_{k,l}$ is the
%     distance between $C_k$ and $v_{k,l}$.}
%   \label{fig:dis}
% \end{figure}

% where $\mathbf{v}_{k,l} = {x_{k,l} \choose y_{k,l}}$ is the axis
% components of a pixel
% $\mathrm{v}_{k,l}$, and $C_k$ is the equivalent for point $C$ on the
% curve given by ${x_k \choose y_k}$. Now consider that the curve is
% distorted by a Gaussian $p(\mathbf{\Phi})$ which makes the displacement $d_{k,l}$ also Gaussian distributed: $p(d_{k,l}) \sim
% \mathcal{N}(d_{k,l}|m_d, \sigma)$, where $m_d$ and $\sigma$ are mean
% and covariance of the distribution. Covariance $\sigma$ is expressed as:
% \begin{equation}
%   \label{eq:cov}
%   \sigma = \mathbf{n}_k \cdot \mathbf{J}_k \cdot \mathbf{\Sigma}_{\Phi}
%   \cdot \mathbf{J}_k^T \cdot \mathbf{n}_k^T\qquad,
% \end{equation}
% where $\mathbf{J}_k$ is the Jacobian of curve $\mathbf{C}$. $\sigma$
% can be taken as the uncertainty of the curve along the normal
% introduced by the covariance
% $\mathbf{\Sigma}_{\mathbf{\Phi}}$, it is a constant and can be
% evaluated offline. The variable
% $\frac{d_{k,l}}{\sigma}$ now becomes a linear function with respect to $\mathbf{\Phi}$.

In order to apply the probabilistic generative models to the
above classification problem,
% calculate the the probability that a point lies on side 1 of the curve
we need to transform the linear function of $\mathbf{\Phi}$ using a
non-linear activation function $f(\cdot)$~\cite{bishop2006pattern}:
\begin{equation}
  \label{eq:nonla}
  a_{v,1} = f(\frac{d_{k,l}}{\sigma})\qquad,
\end{equation}
where $\sigma$
can be taken as the uncertainty of the curve along the normal
introduced by the covariance $\mathbf{\Sigma}_{\mathbf{\Phi}}$. 
$d_{k,l}$ is the distance  between pixel  $\mathrm{v}_{k,l}$ and a given curve.
Unlike in the original CCD implementation we use a non-linear activation functions
called \textit{logistic sigmoid} function given by (and depicted in Fig.~\ref{fig:s-shaped}):
\begin{equation}
  \label{eq:logistic}
  a_{v,1} =
  \frac{1}{1+\mathrm{exp}(\frac{d_{k,l}}{\sqrt{2}\sigma}))}\qquad .
\end{equation}
The term \textit{sigmoid} stands for S-shaped~\cite{bishop2006pattern}. 
\begin{figure} 
    \centering 
    \includegraphics[width=0.48\columnwidth]{logistic.jpg}
    \includegraphics[width=0.48\columnwidth]{erf.jpg}
    \caption{\textbf{Left:} Logistic
  sigmoid function, \textbf{Right:} Probit function from original CCD.}
\label{fig:s-shaped}
\end{figure}

The logistic sigmoid function can be used to transform a broad range
of class-conditional distributions, described by the exponential
family, to a non-linear posterior class probabilities. The edge that the logistic
sigmoid function gives over the probit function is in that it is less sensitive to 
outliers because the logistic sigmoid decays asymptotically like $\mathrm{exp}(-x)$ for $x \rightarrow \infty$, whereas
for the probit activation function the decay is like
$\mathrm{exp}(-x^2)$ (Fig.~\ref{fig:outliers}).
\begin{figure} 
  \includegraphics[width=\columnwidth]{outliers.jpg}
\caption{Classification problem: 
In the the presence of outliers, the probit activation
function (violet line) has a higher misclassification rate.}
\label{fig:outliers}
\end{figure}
% Generally, we can call this approximation process as \textit{fuzzy} (or \textit{smooth})
% assignment. The accuracy of this assignment will increase as the
% uncertainty of curve governed by covariance $\mathbf{\Sigma}_{\mathrm{\Phi}}$ decreases.

With this assignment and following the suggested rule in~\cite{hanek2004contracting}, 
we now start to assign two suitable weighting functions
$\omega_1$, $\omega_2$ to the pixels $\mathrm{v}_{k,l}$ along the
normal for the two sides of the curve. The weighting functions are
defined as:
\begin{equation}
  \label{eq:weight}
  \omega_{1/2}(d_{k,l}) = \mathcal{C}\left(\frac{a_{1/2}(d_{k,l}) -
    \gamma_1}{1-\gamma_2}\right)^4 \left[e^{-d_{k,l}/(2\hat{\sigma}^2)} - e^{-\gamma_2}\right]^+\qquad,
\end{equation}
where $\mathcal{C}$ denotes the normalization constant, $\gamma_1$ equals to $0.5$ (disjoint weight assignment) and $\gamma_2$
equals to $4$ for the truncated Gaussian~\cite{hanek2004contracting}.
% the weight function is shown in Fig.~\ref{fig:weight}.

% \begin{figure} 
% \includegraphics[width=0.48\columnwidth]{images/weight1.jpg}
% \includegraphics[width=0.48\columnwidth]{images/weight2.jpg}
% \caption{The weight functions of the two sides of the contour, a) the
%   weight function along the positive direction (outside) in the normal of the
%   contour. b) the weight function along the negative direction (inside). }
% \label{fig:weight}
% \end{figure}

In addition, the standard
deviation is chosen in order to cover the specified distance $h$,
which yields: 
\begin{equation}
  \label{eq:deviation}
  \hat{\sigma} = \max \left[\frac{h}{\sqrt{2\gamma_2}}, \gamma_4
  \right], \sigma  = \frac{1}{\gamma_3} \hat{\sigma}\qquad,
\end{equation}
with the two additional constants $\gamma_3 = 6$ (linear dependence
between $\sigma$ and $\hat{\sigma}$) and $\gamma_4 = 4$ (minimum
weighting window width) as discussed in~\cite{panin2006efficient}. 

In the implementation of this work,
there are $2 \cdot L \cdot N_C$ distances, fuzzy assignments
and weight functions which leads to as many weight functions being 
evaluated offline and stored in an array. 

Now we have restricted our analysis region of interest in the
limited area, and collected all statistical information required to learn
local statistics. In the next part, we will evaluate the local
statistics. Given the pixel coordinates and their RGB values, assignment and weight
function, local mean vectors $\mathbf{m}_{v,s}$  and local covariance matrix
$\mathbf{\Sigma}_{\mathbf{\Phi}}$ will be derived for each side $s \in
\{1,2\}$ of the curve.
We first calculate the zero, first and second order weighted moments:
\begin{eqnarray}
  \label{eq:localm}
  M_{k,s}^{(0)}(d_{k,l,s}) &=& \sum_{l=0}^{2L-1} \omega_s(d_{k,l})\\
  \mathbf{M}_{k,s}^{(1)}(d_{k,l,s}) &=& \sum_{l=0}^{2L-1} \omega_s(d_{k,l}) \mathrm{I}_{k,l}\\
  \mathbf{M}_{k,s}^{(2)}(d_{k,l,s}) &=& \sum_{l=0}^{2L-1} \omega_s(d_{k,l}) \mathrm{I}_{k,l}\mathrm{I}_{k,l}^T\qquad,
\end{eqnarray}
where $\mathrm{I}_{k,l}$ is just the raw RGB value of a pixel, for a
3-channel image and the values of three components
are  between 0 and 255. The local mean vectors $\mathbf{m}_{v,s}$  and
the local covariance matrices
$\mathbf{\Sigma}_{\mathbf{\Phi}}$  are obtained by:
\begin{eqnarray}
  \label{eq:localmean}
  \mathbf{m}_{k,s} &=& \frac{\mathbf{M}^{(1)}_{k,s}}{M^{(0)}_{k,s}},\\
  \label{eq:localcov}
  \mathbf{\Sigma}_{k,s} &=& \frac{\mathbf{M}^{(2)}_{k,s}}{M^{(0)}_{k,s}}
  - \mathbf{m}_{k,s}\mathbf{m}_{k,s}^T  + \kappa \mathbf{I}\qquad.
\end{eqnarray}
In Eq.~\ref{eq:localcov}, $\kappa \mathbf{I}$  means an identity matrix scaled by
$\kappa$ in order to avoid numerical singularity. Later it is namely
required to calculate the inverse matrix of
$\mathbf{\Sigma}_{k,s}$. In our experiments, we choose $\kappa$ to be
$\kappa = 0.5$, which is efficient to avoid numerical problems in the
process of iteration.

With the local mean vectors $\mathbf{m}_{v,s}$  and the local covariance matrices
$\mathbf{\Sigma}_{k,s}$, we can compute the
likelihood function   $p(\mathbf{I}_{k,l} | \mathbf{m}_{v,1}, \mathbf{m}_{v,2},
  \mathbf{\Sigma}_{v,1}, \mathbf{\Sigma}_{v,1})$ for each pixel
  $\mathrm{v}_{k,l}$. In terms of observation model, the likelihood
  function describes how probable the observed data set is for
  different settings of the parameter vector. Hence, we first establish
  the relation between image data $\mathrm{I}_{k,l}$ and the model
  parameter $\mathbf{\Phi}$. Here we model the pixel value
  $\hat{\mathbf{m}}_{k,l}$ and its covariance $\hat{\mathbf{\Sigma}}_{k,l}$
  for all pixels $\mathrm{v}_{k,l}$ in the vicinity of the curve as the
  linear combination of $\mathbf{m}_{v,1}$ and $\mathbf{m}_{v,2}$:
  \begin{equation}
    \label{eq:meankl}
    \hat{\mathbf{m}}_{k,l} = a_{v,1}(d_{k,l})\mathbf{m}_{v,1} + a_{v,2}(d_{k,l})\mathbf{m}_{v,2}\qquad.
  \end{equation}
To prevent high computational costs we model the covariance matrix $\hat{\mathbf{\Sigma}}_{k,l}$ following the
rule in~\cite{hanek2004fitting}, but we discard the following relation:
\begin{equation}
  \label{eq:sigmakl}
  \hat{\mathbf{\mathbf{\Sigma}}}_{k,l} = a_{v,1}(d_{k,l})\mathbf{\Sigma}_{v,1} + a_{v,2}(d_{k,l})\mathbf{\Sigma}_{v,2}\qquad.
\end{equation}
Now for each observed pixel $\mathbf{I}_{k,l}$, the likelihood
function is given by:
\begin{equation}
  \label{eq:likelihood}
p(\mathbf{I}_{k,l} | \mathbf{m}_{v,1}, \mathbf{m}_{v,2},
  \mathbf{\Sigma}_{v,1}, \mathbf{\Sigma}_{v,1}) = p(\mathbf{I}_{k,l} | \hat{\mathbf{\mathbf{m}}}_{k,l},\hat{\mathbf{\mathbf{\Sigma}}}_{k,l}) \qquad.
\end{equation}
However, we require the likelihood for all pixels in the vicinity of
the curve. If we consider the coupling or other complex relation among
different group of pixels, the problem will become intractable and the cost of computing will be very expensive. We can
avoid these problems if we assume pixels to be drawn independently from the same distribution
, namely independent and identically distributed
(i.i.d)~\cite{bishop2006pattern}. Thus we can model the likelihood function as:
\begin{equation}
  \label{eq:liklihoodall}
  p(\mathbf{I}_{\mathcal{V}} |
  \hat{\mathbf{\mathbf{m}}}_{\mathcal{V}},\hat{\mathbf{\mathbf{\Sigma}}}_{\mathcal{V}})
  = \prod_l \prod_k p(\mathbf{I}_{k,l} | \hat{\mathbf{\mathbf{m}}}_{k,l},\hat{\mathbf{\mathbf{\Sigma}}}_{k,l}) \qquad.
\end{equation}
The index $\mathcal{V}$ indicates quantities for all pixels $v$ in
$\mathcal{V}$. Note that we only take into account those pixels which are
in the vicinity $\mathcal{V}$ of the curve, whereas pixels outside
$\mathcal{V}$ are not considered.

Having the likelihood function of observed pixels, as well as
the input data and prior knowledge, now we can go into the parameters
refinement stage to model the conditional distribution.

\subsection{Refinement of  Parameters}
\label{sec:ref}
In this section, an Iterative Reweighted Least Square (IRLS) process
is presented in order to refine the model parameter vector and the covariance matrix.

With the likelihood function in Eq.~\ref{eq:liklihoodall} and prior distribution in
Eq.~\ref{eq:prior}, we can model the conditional possibility distribution using:
 % we can estimate the $\hat{\Phi}$ using MAP which is based the
% Bayesian treatment.
% Firstly, the posterior distribution holds
\begin{align}
\label{eq:costf}
    p(\mathbf{\Phi}|\mathbf{\mathbf{I}}_{\mathcal{V}}) 
    \propto &
    p(\mathbf{\mathbf{I}_{\mathcal{V}}}
    |\hat{\mathbf{\mathbf{m}}}_{\mathcal{V}}(\mathbf{\Phi}),\hat{\mathbf{\mathbf{\Sigma}}}_{\mathcal{V}}(\mathbf{\Phi}))p(\mathbf{\Phi}
    | \mathbf{m}_{\mathbf{\Phi}},
    \mathbf{\mathbf{\Sigma}}_{\mathbf{\Phi}})\qquad.
\end{align}
The difference between this conditional distribution and posterior
distribution is that here the former function has not been normalized yet.
If applying logarithm operation to the conditional possibility
distribution, we can define a common cost function $\mathcal{Q}$,
which is given by:
\begin{align}
  \label{eq:costd}
  \mathcal{Q} = & -2 \ln \left\{  p(\mathbf{\mathbf{I}_{\mathcal{V}}}
    |\hat{\mathbf{\mathbf{m}}}_{\mathcal{V}}(\mathbf{\Phi}),\hat{\mathbf{\mathbf{\Sigma}}}_{\mathcal{V}}(\mathbf{\Phi}))p(\mathbf{\Phi}
    | \mathbf{m}_{\mathbf{\Phi}},
    \mathbf{\mathbf{\Sigma}}_{\mathbf{\Phi}})\right\}\qquad.
\end{align}
We substitute the estimate $\hat{\mathbf{\Phi}}$ of the model
parameters $\mathbf{\Phi}$ with the mean $\mathbf{m}_{\mathbf{\Phi}}$ of a Gaussian
approximation of the posterior distribution, and thus
$\hat{\mathbf{\Phi}}$ can be evaluated as:
\begin{equation}
  \label{eq:maxcost}
  \hat{\mathbf{\Phi}} =
  \underset{\mathbf{\Phi}}{\arg\max} \
  (\mathcal{Q}) \qquad.
\end{equation}
To optimize $\mathcal{Q}$ based on the estimated $\mathbf{m}_{\mathbf{\Phi}}$,
the approximation to the Hessian matrix can be adopted. First we
compute the partial derivatives of $\mathcal{Q}$:
\begin{equation}
\label{eq:partcost}
\begin{aligned}
&\nabla_{\mathbf{\Phi}}\{{\mathcal{Q}(\mathbf{\Phi})}\} =
2\{{\mathbf{\Sigma}_{\mathbf{\Phi}}}^{-1}\}^{T}{\mathbf{\Phi}}\\ 
&- \sum_{k = 0}^{N_{C}-1} \sum_{l=0}^{2L-1} \left\{\mathcal{J}_{a_{v,1}}^T\hat{\mathbf{\Sigma}}_{k,l}^{-1}\left[\mathrm{I}_{k,l}-\hat{\mathbf{m}}_{k,l}(a_{v,1})\right]\right\}\qquad,
\end{aligned}
\end{equation}
with:
\begin{equation}
  \label{eq:jocob}
  \mathcal{J}_{a_{v,1}} = \left( \mathbf{m}_{k,1} -\mathbf{m}_{k,2} \right)(\nabla_{\mathbf{\Phi}} a_{v,1}(d_{k,l}))^T\qquad.
\end{equation}
Afterwards, the Gauss-Newton approximation to the Hessian
matrix is given by
\begin{equation}
  \label{eq:hessian}
  \mathcal{H}_{\mathbf{\Phi}} \mathcal{Q}  =
  \mathbf{\Sigma}_{\mathbf{\Phi}}^{-1} + \sum_{k = 0}^{N_{C}-1}
  \sum_{l=0}^{2L-1} \left\{\mathcal{J}_{a_{v,1}}^T\hat{\mathbf{\Sigma}}_{k,l}^{-1}\mathcal{J}_{a_{v,1}}\right\}\qquad.
\end{equation}
The overall gradient and Hessian matrices for the optimization
are obtained by adding the prior cost function
derivatives, and the Newton optimization step can finally be
formulated as:
\begin{eqnarray}
\label{eq:newton}
  \mathbf{m}_{\mathbf{\Phi}}^{new} & = &
  \mathbf{m}_{\mathbf{\Phi}} - (\mathcal{H}_{\mathbf{\Phi}}
  \mathcal{Q})^{-1} \nabla_{\mathbf{\Phi}} \mathcal{Q} \nonumber \\
  \mathbf{\Sigma}_{\mathbf{\Phi}}^{new} & = &
  c\mathbf{\Sigma}_{\mathbf{\Phi}} - (1-c)(\mathcal{H}_{\mathbf{\Phi}}
  \mathcal{Q})^{-1}\qquad.
\end{eqnarray}
$c$ is empirically set to $\frac{1}{4}$. Note that the covariance
matrix is updated by an exponential decay rule as well. Coefficient $c$ specifies the
maximum decrease of the covariance within one iteration
step~\cite{hanek2004contracting}. If $c$ is very large, due to the slow reduction of covariance the
convergence process will be very slow. On the other hand if $c$ is
very small, CCD might diverge.


% ALTERNATIVE:
% The robot generates object hypotheses by detecting candidate point clusters in
% the three-dimensional point cloud acquired by the depth sensor. 
% The identified point clusters in the
% point cloud are then back-projected into the captured image
% to form the region of interest that corresponds to the object
% candidate. An accurate back-projection is possible thanks to
% the accurate robot calibration. The sensors are calibrated using a non-linear bundle-
% adjustment-like optimization to estimate various parameters
% of the PR2 Robot. However,
% the resulting polygons of the observed object are not smoothed,
% usually it can not completely encompass the whole object.
% By applying the CCD algorithm, we can accurately obtain the contour of
% a observed object. 

\section{Applications and Experimental Results}
\label{sec:results}
To evaluate the applicability of the herein presented version of the CCD algorithm
we ran three realistic tests in our kitchen lab on the sensor data from the 
PR2 robot. The tests were boostrapped using parameters from
the Table~\ref{tab:ip} and are detailed below. All the tests were performed on a Desktop
computer with a Quad-Core 6200 processor and  4GB memory.

\begin{table}[htbp]
\large
\centering
\resizebox{0.49\textwidth}{!}{\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
experiments & $\gamma_1$& $\gamma_2$ & $\gamma_3$& $\gamma_4$ & $\alpha$
& $\kappa$ & $c$ & $h$ & $\Delta h$ &samples& degrees &dims\\
\hline
Manual & 0.5 & 5 & 7 & 5 & 1.2 & 0.5 &0.25 &40 &2 & 60 & 4 & 6\\
\hline
SIFT  & 0.5 & 5 & 7 & 5 & 1.2 & 0.5 &0.25 &48 &1 & 80 & 4 & 6\\
\hline
Model-based & 0.5 & 5 & 7 & 5 & 1.2 & 0.5 &0.25 &50 &1 & 200 & 4 & 6\\
\hline
\end{tabular}}
\caption{initialization parameters}
\label{tab:ip}
\end{table}

\subsection{Manual Initialization}
In this experiment  a partially occluded book was placed in a clutter. 
The control points of the initial contour were drawn manually. 
If the contour snaps to the book within the tolerance limit
the test is deemed successful. The test image is depicted in Fig.~\ref{fig:book}
in different iteration steps. We ran the CCD algorithm with 40 different initializations and the convergence
failed in two cases. The average convergence time was 3.35$s$, see
also Table~\ref{tab:qr}.
\begin{figure}[htbp]
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 1]{\includegraphics[width=1.5in]{book/0.png}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 5 ]{\includegraphics[width=1.5in]{book/4.png}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 10]{\includegraphics[width=1.5in]{book/9.png}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 20]{\includegraphics[width=1.5in]{book/19.png}}
  \end{minipage} 
  \caption{Segmentation of a book after manual initialization of the contour.}
  \label{fig:book}
\end{figure}

\subsection{SIFT-based Initialization}
\label{sec:sift_init}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\columnwidth]{book/sift_result.png}
  \caption{Segmentation of a book using SIFT-based initialization.}
  \label{fig:sift_result}
\end{figure}

In the second experiments  the initial contour was generated from the SIFT features 
matching a priori learned template of a book as shown in Fig.~\ref{fig:sift_result}. 
We ran the CCD algorithm 100 times which resulted in 9 convergence failures. 
The average convergence time was 3.52$s$ (Table~\ref{tab:qr}). 
We would also like to refer the reader to the video associated with this submission~\footnote{\url{http://youtu.be/0KB3F1GAI24}}.

\subsection{Mesh Model-based Initialization}
\label{sec:tifpc}
We used CCD in order to detect and localize a spread-out T-shirt in the application
of robotic folding. We ran the algorithm 100 times where we substantially varied
the pose of the initially projected T-shirt hull. The algorithm failed 4 times and took
on average 10.15 seconds to converge. While the failed cases are mostly due to the 
too large initial curve displacement, the run time got increased with the number of 
the control points. See also Table~\ref{tab:qr}.

\begin{figure}[htbp]
  \includegraphics[width=0.8\columnwidth]{tshirt/tshirt_pcd.jpg}
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 1]{\includegraphics[width=1.5in]{tshirt/0.png}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 5 ]{\includegraphics[width=1.5in]{tshirt/4.png}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 10]{\includegraphics[width=1.5in]{tshirt/9.png}}
  \end{minipage} 
  \begin{minipage}[t]{0.49\linewidth} 
    \centering 
    \subfloat[iteration 28]{\includegraphics[width=1.5in]{tshirt/27.png}}
  \end{minipage} 
  \caption{\textbf{Top row:} Mesh of the T-shirt. \textbf{Middle and Bottom Row:} 
Detection of the T-shirt using concave hull of above mesh for the application of robotic 
cloth folding. Image courtesy of Christian Bersch.}
  \label{fig:tshirt}
\end{figure}

\begin{table}[htbp]
\centering
\resizebox{0.49\textwidth}{!}{\begin{tabular}{|l|c|c|c|c|}
\hline
Experiments & Failure rate& Run time(s) & Iteration & Tolerance\\
\hline
Manual initialization& 5\% & 3.35 & 26 & 0.001\\
\hline
SIFT initialization & 9\% & 3.52 & 5 & 0.001\\
\hline
Model-based & 4\% & 10.15 & 28 & 0.001\\
\hline
\end{tabular}}
\caption{Experimental Results: Failure rate is the ratio between failures and all test cases. 
Run time is the average run time of all successful test cases, which characterizes the
computational cost. The tolerance is the converge criteria defined as the curve-displacement
between two successive iterations.}
\label{tab:qr}
\end{table}

\subsection{CCD-based Tracker}
A CCD tracker is obtained by applying the CCD algorithm to each
frame of  a sequence of images independently where the output of the parameters 
obtained from the previous frame is used in the current frame. Because  of the 
dependency between the two successive images, the CCD tracker can achieve a high
performance rate and be applied to the time critical problems. The 
video~\footnote{\url{http://youtu.be/0KB3F1GAI24}} demonstrates the tracking of
a book on a cart using 5M pixel camera on a PR2 robot.
% \begin{figure}[htbp]
%   \begin{minipage}[t]{0.49\linewidth} 
%     \centering  
%     \subfloat[Sampled frame 1]{\includegraphics[width=1.5in]{images/sift/1.jpg}}    
%   \end{minipage}% 
%   \begin{minipage}[t]{0.49\linewidth} 
%     \centering 
%     \subfloat[Sampled frame 2]{\includegraphics[width=1.5in]{images/sift/10.jpg}}
%   \end{minipage} 
%   \begin{minipage}[t]{0.49\linewidth} 
%     \centering 
%     \subfloat[Sampled frame 3]{\includegraphics[width=1.5in]{images/sift/30.jpg}}
%     \label{subfig:iteration 3}
%   \end{minipage} 
%   \begin{minipage}[t]{0.49\linewidth} 
%     \centering 
%     \subfloat[Sampled frame 4]{\includegraphics[width=1.5in]{images/sift/45.jpg}}
%   \end{minipage} 
%   \begin{minipage}[t]{0.49\linewidth} 
%     \centering 
%     \subfloat[Sampled frame 5]{\includegraphics[width=1.5in]{images/sift/63.jpg}}
%   \end{minipage} 
%   \begin{minipage}[t]{0.49\linewidth} 
%     \centering 
%     \subfloat[Sampled frame 6]{\includegraphics[width=1.5in]{images/sift/80.jpg}}
%   \end{minipage} 
%   \caption[The tracking result based on SIFT contour initialization]{The
%     CCD tracker successfully tracks the motion of a book.
%   }
%   \label{fig:sifttracker}
% \end{figure}

\section{Conclusions and Future Work}
\label{sec:conclusions}
We presented various extensions to the existing contour fitting algorithm CCD
which makes it applicable to solve various tasks, such as e.g. object
segmentation, needed in the mobile manipulation. The algorithm is robust
to clutter, partial occlusions and even changes of illumination.
In the future we plan to work on CUDA CCD implementation to make the convergence 
faster and use other features than RGB color values in order to improve the stability
even further. 

\section*{Acknowledgment}
 This work was supported by the DFG cluster of excellence \emph{CoTeSys} (Cognition for Technical Systems).
\bibliographystyle{IEEEtran}
\bibliography{references}
\end{document}
